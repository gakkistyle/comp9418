{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 - Assignment 1 - Bayesian Networks as Classifiers\n",
    "\n",
    "## UNSW Sydney, October 2020\n",
    "\n",
    "- Qiwen Zheng - z5240149\n",
    "- Hang Zhu    - z5233612"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "**Submission deadline:** Sunday, 18th October 2020, at 18:00:00.\n",
    "\n",
    "**Late Submission Policy:** The penalty is set at 20% per late day. This is ceiling penalty, so if a group is marked 60/100 and they submitted two days late, they still get 60/100.\n",
    "\n",
    "**Form of Submission:** This is a group assignment. Each group can have up to **two** students. **Only one member of the group should submit the assignment**.\n",
    "\n",
    "You can reuse any piece of source code developed in the tutorials.\n",
    "\n",
    "Submit your files using give. On a CSE Linux machine, type the following on the command-line:\n",
    "\n",
    "``$ give cs9418 ass1 solution.zip``\n",
    "\n",
    "Alternative, you can submit your solution via the [WebCMS](https://webcms3.cse.unsw.edu.au/COMP9418/20T3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "These are the libraries your are allowed to use. No other libraries will be accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make division default to floating-point, saving confusion\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Allowed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import heapq as pq\n",
    "import matplotlib as mp\n",
    "import math\n",
    "from itertools import product, combinations\n",
    "from collections import OrderedDict as odict\n",
    "from graphviz import Digraph\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial task - Initialise graph\n",
    "\n",
    "Create a graph ``G`` that represents the following network by filling in the edge lists.\n",
    "![Bayes Net](BayesNet.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = {\n",
    "    \"BreastDensity\" : [\"Mass\"],\n",
    "    \"Location\" : [\"BC\"],\n",
    "    \"Age\" : [\"BC\"],\n",
    "    \"BC\" : [\"Metastasis\",\"MC\",\"SkinRetract\",\"NippleDischarge\",\"AD\",\"Mass\"],\n",
    "    \"Mass\" : [\"Size\",\"Shape\",\"Margin\"],\n",
    "    \"AD\" : [\"FibrTissueDev\"],\n",
    "    \"Metastasis\" : [ \"LymphNodes\"],\n",
    "    \"MC\" : [],\n",
    "    \"Size\" : [],\n",
    "    \"Shape\" : [],\n",
    "    \"FibrTissueDev\" : [\"SkinRetract\",\"NippleDischarge\",\"Spiculation\"],\n",
    "    \"LymphNodes\" : [],\n",
    "    \"SkinRetract\" : [],\n",
    "    \"NippleDischarge\" : [],\n",
    "    \"Spiculation\" : [\"Margin\"],\n",
    "    \"Margin\" : [],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 1 - Efficient d-separation test\n",
    "\n",
    "Implement the efficient version of the d-separation algorithm in a function ``d_separation(G, X, Z, Y)`` that return a boolean: true if **X** is d-separated from **Y** given **Z** in the graph $G$ and false otherwise.\n",
    "\n",
    "* **X**,**Y** and **Z** are python sets, each containing a set of variable names. \n",
    "* Variable names may be strings or integers, and can be assumed to be nodes of the graph $G$. \n",
    "* $G$ is a graph as defined in tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for d_separation(G, X, Z, Y) in one or more cells here\n",
    "def delete_leaf(G,node):\n",
    "    for start in G.keys():\n",
    "        if node in G[start]:\n",
    "            G[start].remove(node)\n",
    "    G.pop(node)\n",
    "\n",
    "def make_directed(G):\n",
    "    for from_v in G.keys():\n",
    "        for to_v in G[from_v]:\n",
    "            if from_v not in G[to_v]:\n",
    "                G[to_v].append(from_v)\n",
    "            \n",
    "def dfs_search(G,colour,set_Y,node):\n",
    "    colour[node] = 'grey'\n",
    "    if node in set_Y:\n",
    "        return False\n",
    "    \n",
    "    for v in G[node]:\n",
    "        if colour[v] == 'white':\n",
    "            if dfs_search(G,colour,set_Y,v) == False:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def d_separation(G,X,Z,Y):\n",
    "    \n",
    "    #G_copy = G.copy()\n",
    "    G_copy = dict((v, []) for v in G)\n",
    "    for v in G:\n",
    "        G_copy[v] = G[v][:]\n",
    "    \n",
    "    set_all = X | Y | Z\n",
    "    \n",
    "    #first to delete leaves that are not in set_all\n",
    "    leaf_nodes = list()\n",
    "    while True:\n",
    "        for start in G_copy.keys():\n",
    "            if len(G_copy[start]) == 0 and start not in set_all:\n",
    "                \n",
    "                leaf_nodes.append(start)\n",
    "        if len(leaf_nodes) == 0:\n",
    "            break\n",
    "        else:\n",
    "            for node in leaf_nodes:\n",
    "                delete_leaf(G_copy,node)\n",
    "            leaf_nodes.clear()\n",
    "            \n",
    "    #second to delete any outgoing edge from Z\n",
    "    for v in Z:\n",
    "        G_copy[v].clear()\n",
    "        \n",
    "    #then make the G_copy to be undirected graph\n",
    "    make_directed(G_copy)\n",
    "    \n",
    "    #use dfs search to find whether X are separated from Y\n",
    "    colour = {node: 'white' for node in G_copy.keys()}\n",
    "    for v in X:\n",
    "        #if we find a possible path from node of X to node of Y,return false\n",
    "        if not dfs_search(G_copy,colour,Y,v):\n",
    "            return False      \n",
    "    #print (G_copy)   \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "def test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case\")\n",
    "        \n",
    "test(d_separation(G, set(['Age']), set(['BC']), set(['AD'])))\n",
    "test(not d_separation(G, set(['Spiculation','LymphNodes']), set(['MC', 'Size']), set(['Age'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 2 - Estimate Bayesian Network parameters from data\n",
    "\n",
    "Implement a function ``learn_outcome_space(data)`` that learns the outcome space (the valid values for each variable) from the pandas dataframe ``data`` and returns a dictionary ``outcomeSpace`` with these values.\n",
    "\n",
    "Implement a function ``learn_bayes_net(G, data, outcomeSpace)`` that learns the parameters of the Bayesian Network $G$. This function should return a dictionary ``prob_tables`` with the all conditional probability tables (one for each node).\n",
    "\n",
    "- ``G`` is a directed acyclic graph. For this part of the assignment, $G$ should be declared according to the breast cancer Bayesian network presented in the diagram in the assignment specification.\n",
    "- ``data`` is a dataframe created from a csv file containing the relevant data. \n",
    "- ``outcomeSpace`` is defined in tutorials.\n",
    "- ``prob_tables`` is a dict from each variable name (node) to a \"factor\". Factors are defined in tutorial 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_outcome_space(data) in one or more cells here\n",
    "def learn_outcome_space(data):\n",
    "    result = dict.fromkeys(data.columns,set())\n",
    "    for col in result.keys():\n",
    "        result[col] = set(data[col])\n",
    "        result[col] = tuple(result[col])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "with open('bc.csv') as file:\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "outcomeSpace = learn_outcome_space(data)\n",
    "\n",
    "outcomes = outcomeSpace['BreastDensity']\n",
    "answer = ('high', 'medium', 'low')\n",
    "test(len(outcomes) == len(answer) and set(outcomes) == set(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_bayes_net(G, data, outcomeSpace) in one or more cells here\n",
    "\n",
    "#the following three functions(allEqualThisIndex, estProbTable, transposeGraph) are copied from tutorial2\n",
    "def allEqualThisIndex(dict_of_arrays, **fixed_vars):\n",
    "    \"\"\"\n",
    "    Helper function to create a boolean index vector into a tabular data structure,\n",
    "    such that we return True only for rows of the table where, e.g.\n",
    "    column_a=fixed_vars['column_a'] and column_b=fixed_vars['column_b'].\n",
    "    \"\"\"\n",
    "    # base index is a boolean vector, everywhere true\n",
    "    first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
    "    index = np.ones_like(first_array, dtype=np.bool_)\n",
    "    for var_name, var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return index\n",
    "\n",
    "def estProbTable(data, var_name, parent_names, outcomeSpace):\n",
    "    \"\"\"\n",
    "    Calculate a dictionary probability table by ML given\n",
    "    `data`, a dictionary or dataframe of observations\n",
    "    `var_name`, the column of the data to be used for the conditioned variable and\n",
    "    `parent_names`, a tuple of columns to be used for the parents and\n",
    "    `outcomeSpace`, a dict that maps variable names to a tuple of possible outcomes\n",
    "    Return a dictionary containing an estimated conditional probability table.\n",
    "    \"\"\"    \n",
    "    var_outcomes = outcomeSpace[var_name]\n",
    "    parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    prob_table = odict()\n",
    "    \n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "       \n",
    "        parent_index = allEqualThisIndex(data, **parent_vars)\n",
    "        \n",
    "        #for the case that parent index sum is 0,we set each possiblity to be equal\n",
    "        if parent_index.sum() == 0:\n",
    "            for var_outcome in var_outcomes:\n",
    "                prob_table[tuple(list(parent_combination)+[var_outcome])] = 1/len(var_outcomes)\n",
    "            continue\n",
    "\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            \n",
    "            #a slight modify here to apply additive smoothing for naive bayes\n",
    "            value_to_add = (var_index & parent_index).sum()/parent_index.sum()\n",
    "            if value_to_add == 0:\n",
    "                num_to_smooth = len(var_outcomes)\n",
    "                for p_out in parent_outcomes:\n",
    "                    num_to_smooth *= len(p_out)\n",
    "                \n",
    "                prob_table[tuple(list(parent_combination)+[var_outcome])] = (1/(len(data)+num_to_smooth))/(parent_index.sum()/len(data))\n",
    "            else:\n",
    "                prob_table[tuple(list(parent_combination)+[var_outcome])] = (var_index & parent_index).sum()/parent_index.sum()\n",
    "            \n",
    "    return {'dom': tuple(list(parent_names)+[var_name]), 'table': prob_table}\n",
    "\n",
    "def transposeGraph(G):\n",
    "    GT = dict((v, []) for v in G)\n",
    "    for v in G:\n",
    "        for w in G[v]:\n",
    "            GT[w].append(v)\n",
    "    return GT\n",
    "\n",
    "def learn_bayes_net(G, data, outcomeSpace):\n",
    "    G_trans = transposeGraph(G)\n",
    "    \n",
    "    prob_tables = odict()\n",
    "    \n",
    "    for node in G_trans:\n",
    "        prob_tables[node] = estProbTable(data, node, G_trans[node], outcomeSpace)\n",
    "    \n",
    "    return prob_tables\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "prob_tables = learn_bayes_net(G, data, outcomeSpace)\n",
    "test(abs(prob_tables['Age']['table'][('35-49',)] - 0.2476) < 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 3 - Bayesian Network Classification\n",
    "\n",
    "Design a new function ``assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var)`` that uses the test cases in ``data`` to assess the performance of the Bayesian network defined by ``G`` and ``prob_tables``. Implement the efficient classification procedure discussed in the lectures. Such a function should return the classifier accuracy. \n",
    " * ``class_var`` is the name of the variable you are predicting, using all other variables.\n",
    " * ``outcomeSpace`` was created in task 2\n",
    " \n",
    "Remember to remove the variables ``metastasis`` and ``lymphnodes`` from the dataset before assessing the accuracy.\n",
    "\n",
    "Return just the accuracy:\n",
    "\n",
    "``acc = assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var) in one or more cells here\n",
    "\n",
    "# the prob and join function that copied from tut2\n",
    "\n",
    "def prob(factor, *entry):\n",
    "    return factor['table'][entry] \n",
    "\n",
    "def join(f1, f2, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f1`, first factor to be joined.\n",
    "    `f2`, second factor to be joined.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    Returns a new factor with a join of f1 and f2\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, we need to determine the domain of the new factor. It will be union of the domain in f1 and f2\n",
    "    # But it is important to eliminate the repetitions\n",
    "    common_vars = list(f1['dom']) + list(set(f2['dom']) - set(f1['dom']))\n",
    "    \n",
    "    # We will build a table from scratch, starting with an empty list. Later on, we will transform the list into a odict\n",
    "    table = list()\n",
    "    \n",
    "    # Here is where the magic happens. The product iterator will generate all combinations of varible values \n",
    "    # as specified in outcomeSpace. Therefore, it will naturally respect observed values\n",
    "    for entries in product(*[outcomeSpace[node] for node in common_vars]):\n",
    "        \n",
    "        # We need to map the entries to the domain of the factors f1 and f2\n",
    "        entryDict = dict(zip(common_vars, entries))\n",
    "        f1_entry = (entryDict[var] for var in f1['dom'])\n",
    "        f2_entry = (entryDict[var] for var in f2['dom'])\n",
    "        \n",
    "        p1 = prob(f1, *f1_entry)           # Use the fuction prob to calculate the probability in factor f1 for entry f1_entry \n",
    "        p2 = prob(f2, *f2_entry)           # Use the fuction prob to calculate the probability in factor f2 for entry f2_entry \n",
    "        \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, p1 * p2))\n",
    "    return {'dom': tuple(common_vars), 'table': odict(table)}\n",
    "\n",
    "\n",
    "#joint the prob tables that related to class_var\n",
    "def markov_blanket_joint(G, prob_tables,outcomeSpace, class_var):\n",
    "    p = prob_tables[class_var]\n",
    "\n",
    "    for node in G[class_var]:\n",
    "    \n",
    "    #full joint\n",
    "        #remove Metastasis and LymphNodes\n",
    "        if  node != 'Metastasis' and node != 'LymphNodes':\n",
    "            p= join(p,prob_tables[node], outcomeSpace)  \n",
    "    return p\n",
    "\n",
    "# according to lec, we only need a subset of whole distribution.The distribution we need is Markov blanket of class_var\n",
    "def assess_bayes_net(G, prob_tables, data, outcomeSpace, class_var):\n",
    "    \n",
    "    markov_joint_table = markov_blanket_joint(G, prob_tables,outcomeSpace,class_var)\n",
    " \n",
    "    markov_blanket_list = list(markov_joint_table['dom'])\n",
    "    index = markov_blanket_list.index(class_var)\n",
    "    \n",
    "    #count the correct forecast\n",
    "    correct = 0\n",
    "    \n",
    "    #get the needed columns of data\n",
    "    data_m_b = data[markov_blanket_list]\n",
    "    \n",
    "    for ind,data_once in data_m_b.iterrows():\n",
    "        data_list = list(data_once)\n",
    "        p = 0\n",
    "        forecast=None\n",
    "        for possible_v in outcomeSpace[class_var]:\n",
    "            data_list[index] = possible_v\n",
    "            p_once = markov_joint_table['table'][tuple(data_list)]\n",
    "            if p_once > p:\n",
    "                p = p_once\n",
    "                forecast = possible_v\n",
    "        if forecast == data_once[class_var]:\n",
    "            correct += 1\n",
    "    return correct/len(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84225"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "acc = assess_bayes_net(G, prob_tables, data, outcomeSpace, 'BC')\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a function ``cv_bayes_net(G, data, class_var)`` that uses ``learn_outcome_space``, ``learn_bayes_net``and ``assess_bayes_net`` to learn and assess a Bayesian network in a dataset using 10-fold cross-validation. Compute and report the average accuracy over the ten cross-validation runs as well as the standard deviation, e.g.\n",
    "\n",
    "``acc, stddev = cv_bayes_net(G, data, class_var)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cv_bayes_net(G, data, class_var) in one or more cells here\n",
    "\n",
    "def cv_bayes_net(G, data, class_var):\n",
    "    #divide the whole data set to 10 equal subsets\n",
    "    unit = int(len(data)/10)\n",
    "    start = 0\n",
    "    end = start + unit\n",
    "    \n",
    "    #learn the outcomespace\n",
    "    outcomeSpace = learn_outcome_space(data)\n",
    "    acc_list = list()\n",
    "    \n",
    "    #each time we drop data from start to end as test data and rests are train data\n",
    "    for i in range(10):\n",
    "        data_train = data.drop([e for e in range(start,end)])\n",
    "        data_test = data.loc[start:end-1]\n",
    "        \n",
    "        prob_tables = learn_bayes_net(G, data_train, outcomeSpace)\n",
    "        acc_once = assess_bayes_net(G, prob_tables, data_test, outcomeSpace, class_var)\n",
    "        acc_list.append(acc_once)\n",
    "        \n",
    "        start = end\n",
    "        end = start + unit\n",
    "        \n",
    "    acc_averge = np.mean(acc_list)\n",
    "    std_dev = np.std(acc_list)\n",
    "    return acc_averge,std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.638650894165039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8411"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "#count down time\n",
    "import time\n",
    "\n",
    "a_task3 = time.time()\n",
    "acc1, stddev = cv_bayes_net(G, data, 'BC')\n",
    "b_task3 = time.time()\n",
    "time_t3 = b_task3-a_task3\n",
    "print(time_t3)\n",
    "acc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 4 - Naïve Bayes Classification\n",
    "\n",
    "Design a new function ``assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var)`` to classify and assess the test cases in a dataset ``data`` according to the Naïve Bayes classifier. To classify each example, use the log probability trick discussed in the lectures. This function should return the accuracy of the classifier in ``data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var) in one or more cells here\n",
    "\n",
    "def assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var):\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    for index,data_once in data.iterrows():\n",
    "        p = np.iinfo(np.int16).min\n",
    "        forcast = None\n",
    "        for possible_v in outcomeSpace[class_var]:\n",
    "            p_once = np.log(prob_tables[class_var]['table'][(possible_v,)])\n",
    "            for node in G[class_var]:\n",
    "                 p_once += np.log(prob_tables[node]['table'][(possible_v,data_once[node],)])\n",
    "            if p_once > p:\n",
    "                p = p_once\n",
    "                forcast = possible_v\n",
    "        if forcast == data_once[class_var]:\n",
    "            correct += 1\n",
    "    return correct/len(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "#acc = assess_naive_bayes(G, prob_tables, data, outcomeSpace, 'BC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a new function ``cv_naive_bayes(data, class_var)`` that uses ``assess_naive_bayes`` to assess the performance of the Naïve Bayes classifier in a dataset ``data``. To develop this code, perform the following steps:\n",
    "\n",
    "1. Use 10-fold cross-validation to split the data into training and test sets.\n",
    "\n",
    "2. Implement a function ``learn_naive_bayes_structure(outcomeSpace, class_var)`` to create and return a Naïve Bayes graph structure from ``outcomeSpace`` and ``class_var``. \n",
    "\n",
    "3. Use ``learn_bayes_net(G, data, outcomeSpace)`` to learn the Naïve Bayes parameters from a training set ``data``. \n",
    "\n",
    "4. Use ``assess_naive_bayes(G, prob_tables, data, outcomeSpace, class_var)`` to compute the accuracy of the Naïve Bayes classifier in a test set ``data``. Remember to remove the variables ``metastasis`` and ``lymphnodes`` from the dataset before assessing the accuracy.\n",
    "\n",
    "Do 10-fold cross-validation, same as above, and return ``acc`` and ``stddev``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_naive_bayes_structure(outcomeSpace, class_var) in one or more cells here\n",
    "\n",
    "def learn_naive_bayes_structure(outcomeSpace, class_var):\n",
    "    \n",
    "    #make a copy of outcomespace since we want to delete the two nodes\n",
    "    outcomeSpace_copy = {}\n",
    "    for key in outcomeSpace.keys():\n",
    "        outcomeSpace_copy[key] = outcomeSpace[key]\n",
    "    outcomeSpace_copy.pop('Metastasis', None)\n",
    "    outcomeSpace_copy.pop('LymphNodes', None)\n",
    "    naive_graph = dict.fromkeys(outcomeSpace_copy.keys(),[])\n",
    "    value_list = list(outcomeSpace_copy.keys())\n",
    "    value_list.remove(class_var)\n",
    "   \n",
    "    naive_graph[class_var] = value_list\n",
    "            \n",
    "    return naive_graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "naive_graph = learn_naive_bayes_structure(outcomeSpace, 'BC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cv_naive_bayes(data, class_var) in one or more cells here\n",
    "\n",
    "def cv_naive_bayes(data, class_var):\n",
    "    \n",
    "    #divide the whole data set to 10 equal subsets\n",
    "    unit = int(len(data)/10)\n",
    "    start = 0\n",
    "    end = start + unit\n",
    "    \n",
    "    #learn the outcomespace\n",
    "    outcomeSpace = learn_outcome_space(data)\n",
    "    acc_list = list()\n",
    "    G_NB = learn_naive_bayes_structure(outcomeSpace, class_var)\n",
    "    #each time we drop data from start to end as test data and rests are train data\n",
    "    for i in range(10):\n",
    "        data_train = data.drop([e for e in range(start,end)])\n",
    "        #print(len(data_train))\n",
    "        data_test = data.loc[start:end-1]\n",
    "        #print(len(data_test))\n",
    "        \n",
    "        \n",
    "        prob_tables = learn_bayes_net(G_NB, data_train, outcomeSpace)\n",
    "        acc_once = assess_naive_bayes(G_NB, prob_tables, data_test, outcomeSpace, class_var)\n",
    "        acc_list.append(acc_once)\n",
    "        \n",
    "        start = end\n",
    "        end = start + unit\n",
    "        \n",
    "    acc_averge = np.mean(acc_list)\n",
    "    std_dev = np.std(acc_list)\n",
    "    return acc_averge,std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.699355125427246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7919"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "import time\n",
    "a_t4 = time.time()\n",
    "acc2, stddev = cv_naive_bayes(data, 'BC')\n",
    "b_t4  = time.time()\n",
    "time_t4 = b_t4-a_t4\n",
    "print(time_t4)\n",
    "acc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 5 - Tree-augmented Naïve Bayes Classification\n",
    "\n",
    "Similarly to the previous task, implement a Tree-augmented Naïve Bayes (TAN) classifier and evaluate your implementation in the breast cancer dataset. Design a function ``learn_tan_structure(data, outcomeSpace, class_var)`` to learn the TAN structure (graph) from the ``data`` and returns such a structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for learn_tan_structure(data, outcomeSpace, class_var) in one or more cells here\n",
    "\n",
    "def compute_MI(data,node1,node2,class_var,class_var_ptable,outcomeSpace):\n",
    "    result = 0\n",
    "    data_len = len(data)\n",
    "    for v1 in outcomeSpace[node1]:\n",
    "        data_v1 = data[data[node1] == v1]\n",
    "        for v2 in outcomeSpace[node2]:\n",
    "            data_v2 = data[data[node2] == v2]\n",
    "            data_v1_v2 = data_v2[data_v2[node1] == v1]\n",
    "            for v3 in outcomeSpace[class_var]:\n",
    "                #MOST time spent on this part\n",
    "                p1 = len(data_v1_v2[data_v1_v2[class_var] == v3])\n",
    "                if p1 != 0:\n",
    "                     result += p1*np.log(p1/((len(data_v1[data_v1[class_var] == v3])/data_len)*(len(data_v2[data_v2[class_var] == v3])/class_var_ptable[v3])))\n",
    "    return result\n",
    "\n",
    "# modified from tut1 to generate the maximum spanning tree\n",
    "def prim(G, s):\n",
    " \n",
    "    S = {s}  \n",
    "    Q = []  \n",
    "    tree = []\n",
    "    for e in G[s]:\n",
    "        pq.heappush(Q, [e[1], s, e[0]])\n",
    "        pq._heapify_max(Q)\n",
    "    while len(Q) > 0:\n",
    "        \n",
    "        [cost, v, u] = pq.heappop(Q)\n",
    "        pq._heapify_max(Q)\n",
    "       \n",
    "        if not u in S:  \n",
    "            S.add(u)\n",
    "            tree.append([v, u, cost])\n",
    "            for e in G[u]:\n",
    "                if not e[0] in S:\n",
    "                    # Edge e is of interest, let's store in the priority queue for future analysis\n",
    "                    pq.heappush(Q, [e[1], u, e[0]])   \n",
    "                    pq._heapify_max(Q)\n",
    "    return tree\n",
    "\n",
    "def learn_tan_structure(data, outcomeSpace, class_var):\n",
    "    \n",
    "    data.drop(['Metastasis','LymphNodes'],axis=1)\n",
    "    \n",
    "    outcomeSpace_copy = {}\n",
    "    for key in outcomeSpace.keys():\n",
    "        outcomeSpace_copy[key] = outcomeSpace[key]\n",
    "    outcomeSpace_copy.pop('Metastasis', None)\n",
    "    outcomeSpace_copy.pop('LymphNodes', None)\n",
    "    \n",
    "    #add_node is a list with all keys except class_var,every time we delete a node from added_node and add it to tan\n",
    "    added_nodes = list(outcomeSpace_copy.keys())\n",
    "    added_nodes.remove(class_var)\n",
    "    \n",
    "    #compute possiblity table for class_var\n",
    "    class_ptable = dict()\n",
    "    for possible_v in outcomeSpace_copy[class_var]:\n",
    "        p = len(data[data[class_var] == possible_v])/len(data)\n",
    "        class_ptable[possible_v] = p\n",
    "    \n",
    "    #the undircted graph used to compute maximum spaning tree\n",
    "    undircted_graph = dict.fromkeys(added_nodes)\n",
    "    for key in undircted_graph.keys():\n",
    "        undircted_graph[key] = []\n",
    "    \n",
    "    # the MI is symmetric,the node pair is used to take record of the pair we already computed and do not need to compute twice\n",
    "    node_pair = []\n",
    "    for node1 in added_nodes:\n",
    "        for node2 in added_nodes:\n",
    "            if node1 != node2 and [node2,node1] not in node_pair:\n",
    "                MI_once = compute_MI(data,node1,node2,class_var,class_ptable,outcomeSpace_copy)\n",
    "                undircted_graph[node1].append([node2,MI_once])\n",
    "                undircted_graph[node2].append([node1,MI_once])\n",
    "                node_pair.append([node1,node2])\n",
    "    \n",
    "    tree = prim(undircted_graph,added_nodes[0])\n",
    "\n",
    "    #the result tan structure\n",
    "    tan = dict.fromkeys(added_nodes+[class_var])\n",
    "    for key in tan.keys():\n",
    "        tan[key] = []\n",
    "        \n",
    "    for edge in tree:\n",
    "        tan[edge[0]].append(edge[1])\n",
    "        \n",
    "    # class_var points to every other node\n",
    "    tan[class_var] = [node for node in added_nodes]\n",
    "    \n",
    "    return tan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "tan_graph = learn_tan_structure(data, outcomeSpace, 'BC')\n",
    "test(len(tan_graph['BC']) == len(tan_graph)-1)\n",
    "test('FibrTissueDev' in tan_graph['Spiculation'] or 'Spiculation' in tan_graph['FibrTissueDev'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the other tasks, design a function ``cv_tan(data, class_var)`` that uses 10-fold cross-validation to assess the performance of the TAN classifier from ``data``. Remember to remove the variables ``metastasis`` and ``lymphnodes`` from the dataset before assessing the accuracy. This function should use the ``learn_tan_structure`` as well as other functions defined in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cv_tan(data, class_var) in one or more cells here\n",
    "\n",
    "def cv_tan(data, class_var):\n",
    "    \n",
    "    #divide the whole data set to 10 equal subsets\n",
    "    unit = int(len(data)/10)\n",
    "    start = 0\n",
    "    end = start + unit\n",
    "    \n",
    "    #learn the outcomespace\n",
    "    outcomeSpace = learn_outcome_space(data)\n",
    "    acc_list = list()\n",
    "    \n",
    "    #each time we drop data from start to end as test data and rests are train data\n",
    "    for i in range(10):\n",
    "        data_train = data.drop([e for e in range(start,end)])\n",
    "        data_test = data.loc[start:end-1]\n",
    "        \n",
    "        G_tan = learn_tan_structure(data_train, outcomeSpace,class_var)\n",
    "        prob_tables = learn_bayes_net(G_tan, data_train, outcomeSpace)\n",
    "         \n",
    "        acc_once = assess_bayes_net(G_tan, prob_tables, data_test, outcomeSpace, class_var)\n",
    "        \n",
    "        acc_list.append(acc_once)\n",
    "        \n",
    "        start = end\n",
    "        end = start + unit\n",
    "        \n",
    "    acc_averge = np.mean(acc_list)\n",
    "    std_dev = np.std(acc_list)\n",
    "    return acc_averge,std_dev\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.9714319705963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83285"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "## TEST CODE\n",
    "\n",
    "import time\n",
    "a_t5 = time.time()\n",
    "\n",
    "acc3, stddev = cv_tan(data, 'BC')\n",
    "\n",
    "b_t5 = time.time()\n",
    "time_t5 = b_t5-a_t5\n",
    "print(time_t5)\n",
    "acc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 6 - Report\n",
    "\n",
    "Write a report (**with less than 500 words**) summarising your findings in this assignment. Your report should address the following:\n",
    "\n",
    "a. Make a summary and discussion of the experimental results (accuracy). Use plots to illustrate your results.\n",
    "\n",
    "b. Discuss the complexity of the implemented algorithms.\n",
    "\n",
    "Use Markdown and Latex to write your report in the Jupyter notebook. Develop some plots using Matplotlib to illustrate your results. Be mindful of the maximum number of words. Please, be concise and objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop your report in one or more cells here\n",
    "\n",
    "a : The overall result of predicting BC is relatively good, the plot of acc of predicting BC with data and graph provided(for t3) is shown as following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.title('accuracy plot for t3-5')\n",
    "x = ['t3','t4','t5']\n",
    "y = [acc1,acc2,acc3]\n",
    "pyplot.xlabel('Method')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.plot(x,y,'ob')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can conclude that the t3 bayesian network has the highest average acc,since it has complete information of the dependency relationship.The average accuarcy rate of t5 tree-argumented naive bayes(TAN) is slightly fall behind, around 83.TAN method uses mutual information to dig inner relationship behind data so that we can build bayesian graph with data.Naive bayes of t4 gives us the lowest average acc,below 80 percent.This result is easy to predict since it only needs data and takes the class_var(BC) as the root node pointing to every other nodes(except Metastasis and LymphNodes),so it loses information of dependency within data.\n",
    "Also because of the long time doing t5 cv part,we also want to take record of the time spent on t3,t4,t5 on the laptop(macbook pro 2.2GHz i7 processor and 16GB memory) .The plot revealing time of computing t3,t4,t5 on this laptop is shown as the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.title('running time plot for t3-5')\n",
    "x = ['t3','t4','t5']\n",
    "y = [time_t3,time_t4,time_t5]\n",
    "pyplot.xlabel('Method')\n",
    "pyplot.ylabel('running time')\n",
    "pyplot.plot(x,y,'ob')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the running time plot we can see the task3 bayesian network runs fastest, less than 5 seconds.The naive bayes model also get quick result with less than 20 seconds.But task5 TAN method runs really slow,around 160s to get final 10-fold cross validation result,the reason of which is the enormous time spent on computing MI among nodes and do the full joint table.After writing code to test the time on each part of t5(the code does not show on the report since it is messy),we find each time generating tree graph is about 6s and getting full joint table is about 9s on the laptop.This two parts really dominate complexity and we can not find out way to refine it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b: The complexity of the implemented algorithms for the five tasks.\n",
    "\n",
    "task1: the time and space complexity of D-separation is O(EN),where E is the number of edges of graph and N is the number of graph nodes,it is easy to conclude this since the time and space of this procedure are linear in the size of the DAG.\n",
    "\n",
    "task2: the time of the learn outcome step is O(S),where S is the number of columns of data.While the space complexity is O(SO) with S the number of columns of data and O the number of outcome of each column.\n",
    "The time and space complexity of learn table function is O(N$O^{E}$),where N is the number of node of graph,O is the maximum number among all the outcome of each column,E is the maximum number of edges incomming to one node.\n",
    "\n",
    "task3: the time for assessing accuracy of the test set is O($P^{E}$+TO),where P is the maximum rows of CPT of all the outgoing nodes of class_var(BC), E is the number of outgoing nodes of BC,T is the total number of test set,O is the number of outcome of class_var,for the graph of task3,the impact of exponential growth is relatively slow since E is only a small subset of the whole graph.The space complexity is O($P^{E}$),the varible defination i are just as previous one.\n",
    "The cv part time complexity is O(K($P^{E}$+TO)),where K is k-fold cross validation and here is 10,the rest parameters are same as before.Space complexity is O($P^{E}$ + T),where T is total number of data,the rests are the same meaning.\n",
    "\n",
    "task4: the time complexity of assessing accuracy is O(TOE),where T is total number of rows of data,O is the number of outcome of class_var and E is the number of outgoing nodes of BC.It is O(1) space complexity for this function.\n",
    "Learn naive bayes is O(1) time complexity and O(N) space complexity,where N is number of nodes.\n",
    "CV part time complexity is O(KTOE),where K is k-fold cross validation and here is 10,the rest TOE is the same as assessing accuracy.\n",
    "\n",
    "task5: the time complexity of learning tan structure is O($N^{2}$$O^{3}$),where N is the number of nodes except class_var,Metastasis,LymphNodes and O is the maximum number of outcome among these nodes.The reason is because the time is dominated by the computing mutual information part.The space complexity is O($N^{2}$),N is the defination as previous one.  \n",
    "the time complexity of CV part is O(K($N^{2}$$O^{3}$+$P^{E}$+TO)),the defination of parameters is the same as t3 cv part and the learning tan part.This time since class_var points to every node, E becomes larger, so joining tables part grows exponationally and thus it takes so much time to do this part.Space complexity is about O($N^{2}$+$P^{E}$+T),same meaning as before.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
