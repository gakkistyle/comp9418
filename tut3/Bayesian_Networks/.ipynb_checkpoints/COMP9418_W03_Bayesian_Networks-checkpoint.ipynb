{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Networks\n",
    "\n",
    "**COMP9418-20T3, W03 Tutorial**\n",
    "\n",
    "- Instructor: Gustavo Batista\n",
    "- School of Computer Science and Engineering, UNSW Sydney\n",
    "- Questions adapted by Gustavo Batista from a Jupyter notebook developed by Daniel Mackinlay and Edwin V. Bonilla\n",
    "- Last Update 24th Setember at 18:00, 2020\n",
    "$$\n",
    "% macros\n",
    "\\newcommand{\\indep}{\\perp \\!\\!\\!\\perp}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's tutorial, we will start exploring representation and inference with Bayesian networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "You will need certain packages installed to run this notebook.\n",
    "\n",
    "If you are using ``conda``'s default\n",
    "[full installation](https://conda.io/docs/install/full.html),\n",
    "these requirements should all be satisfied already.\n",
    "\n",
    "If you are using ``virtualenv`` or other native package management,\n",
    "you may need to run this command:\n",
    "\n",
    "```python\n",
    "pip3 install pandas\n",
    "```\n",
    "\n",
    "To render a visualization of some graphical models, you also need to install Graphviz [download page](http://www.graphviz.org/download). We have already used this library in Tutorial 1, thus, you should have it installed. If you do not have it and use the conda installation, then use the command ```conda install python-graphviz```. \n",
    "\n",
    "You will also need to download the preprocessed `icu_diag.csv` data set (see data file for this tutorial in WebCMS3) and put it in the same folder as this notebook.\n",
    "\n",
    "Once we have done all that, we import some useful modules for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make division default to floating-point, saving confusion\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# combinatorics\n",
    "from itertools import product, combinations\n",
    "# ordered dictionaries are useful for keeping ordered sets of varibles\n",
    "from collections import OrderedDict as odict\n",
    "#visualise our graph\n",
    "from graphviz import Digraph\n",
    "\n",
    "# table formating for screen output\n",
    "from tabulate import tabulate\n",
    "\n",
    "# easier debugging display\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will need the `printFactor` and `prob` functions defined in the previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printFactor(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, a factor to print on screen\n",
    "    \"\"\"\n",
    "    # Create a empty list that we will fill in with the probability table entries\n",
    "    table = list()\n",
    "    \n",
    "    # Iterate over all keys and probability values in the table\n",
    "    for key, item in f['table'].items():\n",
    "        # Convert the tuple to a list to be able to manipulate it\n",
    "        k = list(key)\n",
    "        # Append the probability value to the list with key values\n",
    "        k.append(item)\n",
    "        # Append an entire row to the table\n",
    "        table.append(k)\n",
    "    # dom is used as table header. We need it converted to list\n",
    "    dom = list(f['dom'])\n",
    "    # Append a 'Pr' to indicate the probabity column\n",
    "    dom.append('Pr')\n",
    "    print(tabulate(table,headers=dom,tablefmt='orgtbl'))\n",
    "    \n",
    "def prob(factor, *entry):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, a dictionary of domain and probability values,\n",
    "    `entry`, a list of values, one for each variable in the same order as specified in the factor domain.\n",
    "    \n",
    "    Returns p(entry)\n",
    "    \"\"\"\n",
    "\n",
    "    return factor['table'][entry]     # insert your code here, 1 line    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## `pandas`\n",
    "\n",
    "We will be using an external library for the loading tabular data: `pandas.DataFrame` is somewhat similar to `R`. \n",
    "If you wish to know more about that, [check out the Pandas intro](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html). We will mostly be ignoring this library, except to load data and display it in nice tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# The Data\n",
    "\n",
    "## Loading the data\n",
    "\n",
    "These data correspond to the problem in the theory part of the tutorial for this week, i.e. the Bayesian network for medical diagnosis in an intensive care unit (ICU). The data are in `csv` format.\n",
    "We can load this in several ways in python, but the most convenient for this purpose \n",
    "is to load it as a `DataFrame` in `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(open('icu_diag.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded data frame is an attribute-value table. It contais 1000 rows (examples), each one correponding to a patient in the intensive care unit. Each row has nine colums (attributes). Each column correponds to one variable in the Bayesian network. The next figure illustrates the network.\n",
    "\n",
    "![ICU Graph](img/ICU_graph.png \"Graph exercise\")\n",
    "\n",
    "We can use the command ``data.head()`` to display the first $n$ rows (default = 5) of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the cariables are encoded as follows:\n",
    "\n",
    "| Variable  |  Value  |  Coding |\n",
    "| :-------: | :-----: | ------: |\n",
    "| H, L, A   |  False  | 0       |\n",
    "| H, L, A   |  True   | 1       |\n",
    "| V, S, T   |  Low    | 0       |\n",
    "| V, S, T   |  High   | 1       |\n",
    "| C, O, B   |  Low    | 0       |\n",
    "| C, O, B   |  Medium | 1       |\n",
    "| C, O, B   |  High   | 2       |\n",
    "\n",
    "For now, we will keep this encoding as provided in the data file. However, replacing the numerical codes by symbolic labels may improve the results readability. To keep this notebook short, we will leave this extension as an exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the probability tables from the data\n",
    "\n",
    "We need to estimate a discrete distribution\n",
    "for each (conditional) probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Let's first represent this graph using the adjacency list discussed in the tutorial 01. We created a stub for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {                 # ICU graph adjacency list. 9 lines\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use GraphViz to display the graph representation, so we can assure we did not forget any edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = Digraph(comment='ICU Graph')\n",
    "\n",
    "for v in graph:\n",
    "    dot.node(str(v))\n",
    "\n",
    "for v in graph:\n",
    "    for w in graph[v]:\n",
    "        dot.edge(str(v), str(w))\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to declare a data structure with the possible outcomes for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible outcomes, by variable\n",
    "outcomeSpace = dict(\n",
    "    H=(0,1),\n",
    "    L=(0,1),\n",
    "    A=(0,1),\n",
    "    V=(0,1),\n",
    "    S=(0,1),\n",
    "    T=(0,1),\n",
    "    C=(0,1,2),\n",
    "    O=(0,1,2),\n",
    "    B=(0,1,2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we estimate parameters by constructing conditional distributions for each node in our graph.\n",
    "We will take the proportions of empirical counts as estimates of the probabilities of the counted outcomes, i.e.\n",
    "$$\n",
    "\\hat{p}(\\boldsymbol{X_i}=\\boldsymbol{x},\\boldsymbol{Y_i}=\\boldsymbol{y})=\\frac{N_{\\boldsymbol{x}, \\boldsymbol{y}}}{N},\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\hat{p}(\\boldsymbol{X_i}=\\boldsymbol{x}\\mid\\boldsymbol{Y_i}=\\boldsymbol{y})=\\frac{N_{\\boldsymbol{x}, \\boldsymbol{y}}}{N_\\boldsymbol{y}},\n",
    "$$\n",
    "\n",
    "where $N_{\\boldsymbol{x}, \\boldsymbol{y}}$ is the number of observations of that outcome,\n",
    "$$N_{\\boldsymbol{x}, \\boldsymbol{y}}:=\\sum_i\\boldsymbol{X_i}=\\boldsymbol{x}\\cap\\boldsymbol{Y_i}=\\boldsymbol{y},$$ and $N$ is the total number of observations.\n",
    "\n",
    "Later, we will see this procedure of estimating parameters corresponds to the Maximum Likelihood Estimate (MLE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is another helper function. This will calculate joint occurrence probability tables.\n",
    "you invoke it like this\n",
    "```\n",
    "prob_table = est_prob_table(data, 'V', ['H', 'L'])\n",
    "```\n",
    "to estimate all conditional occurrence probabilities of $V|H,L$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allEqualThisIndex(dict_of_arrays, **fixed_vars):\n",
    "    \"\"\"\n",
    "    Helper function to create a boolean index vector into a tabular data structure,\n",
    "    such that we return True only for rows of the table where, e.g.\n",
    "    column_a=fixed_vars['column_a'] and column_b=fixed_vars['column_b'].\n",
    "    \n",
    "    This is a simple task, but it's not *quite* obvious\n",
    "    for various obscure technical reasons.\n",
    "    \n",
    "    It is perhaps best explained by an example.\n",
    "    \n",
    "    >>> all_equal_this_index(\n",
    "    ...    {'X': [1, 1, 0], Y: [1, 0, 1]},\n",
    "    ...    X=1,\n",
    "    ...    Y=1\n",
    "    ... )\n",
    "    [True, False, False]\n",
    "    \"\"\"\n",
    "    # base index is a boolean vector, everywhere true\n",
    "    first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
    "    index = np.ones_like(first_array, dtype=np.bool_)\n",
    "    for var_name, var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return index\n",
    "\n",
    "def estProbTable(data, var_name, parent_names, outcomeSpace):\n",
    "    \"\"\"\n",
    "    Calculate a dictionary probability table by ML given\n",
    "    `data`, a dictionary or dataframe of observations\n",
    "    `var_name`, the column of the data to be used for the conditioned variable and\n",
    "    `parent_names`, a tuple of columns to be used for the parents and\n",
    "    `outcomeSpace`, a dict that maps variable names to a tuple of possible outcomes\n",
    "    Return a dictionary containing an estimated conditional probability table.\n",
    "    \"\"\"    \n",
    "    var_outcomes = outcomeSpace[var_name]\n",
    "    parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    prob_table = odict()\n",
    "    \n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "        parent_index = allEqualThisIndex(data, **parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            prob_table[tuple(list(parent_combination)+[var_outcome])] = (var_index & parent_index).sum()/parent_index.sum()\n",
    "            \n",
    "    return {'dom': tuple(list(parent_names)+[var_name]), 'table': prob_table}\n",
    "\n",
    "\n",
    "##############################\n",
    "# Test code\n",
    "##############################\n",
    "printFactor(estProbTable(data, 'V', ['H', 'L'], outcomeSpace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use the above function to calculate the probability tables for all 9 variables of the ICU Bayesian Network. \n",
    "\n",
    "However, notice that the `estProbTable(data, var_name, parent_names, outcomeSpace)` requires the variable name (`var_name`) and the parent names (`parent_names`). We do not have this information readly available. The adjacency list provides the children of each node, not its parents.\n",
    "\n",
    "The question is, how can be invert the graph data structure so that each node will point to its parents? Yes, the answer is the graph transpose operation, reviwed in Tutorial 01.\n",
    "\n",
    "We implemented this function for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transposeGraph(G):\n",
    "    GT = dict((v, []) for v in G)\n",
    "    for v in G:\n",
    "        for w in G[v]:\n",
    "            GT[w].append(v)\n",
    "\n",
    "    return GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphT = transposeGraph(graph)\n",
    "\n",
    "dot = Digraph(comment='Direct transpose graph GT')\n",
    "\n",
    "for v in graphT:\n",
    "    dot.node(str(v))\n",
    "\n",
    "for v in graphT:\n",
    "    for w in graphT[v]:\n",
    "        dot.edge(str(v), str(w))\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `estProbTable(data, var_name, parent_names, outcomeSpace)` function to calculate probability tables for all 9 variables in our DAG (Bayesian network structure in the theory part of the tutorial). Store them in a dictionary called `cond_tables_ml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_tables_ml = odict()\n",
    "for node, parents in graphT.items():\n",
    "    cond_tables_ml[node] = None             # Estimate the probability for a single table. 1 line\n",
    "\n",
    "##############################\n",
    "# Test code\n",
    "##############################\n",
    "print('estimated P(H)=')\n",
    "pprint(dict(cond_tables_ml['H']))\n",
    "print()\n",
    "print('estimated P(V|H,L)=')\n",
    "pprint(dict(cond_tables_ml['V']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented this code correctly, you should see an output like this:\n",
    "    \n",
    "```\n",
    "estimated P(H)=\n",
    "|   H |    Pr |\n",
    "|-----+-------|\n",
    "|   0 | 0.801 |\n",
    "|   1 | 0.199 |\n",
    "\n",
    "\n",
    "estimated P(V|H,L)=\n",
    "|   L |   H |   V |        Pr |\n",
    "|-----+-----+-----+-----------|\n",
    "|   0 |   0 |   0 | 0.0447958 |\n",
    "|   0 |   0 |   1 | 0.955204  |\n",
    "|   0 |   1 |   0 | 0.994764  |\n",
    "|   0 |   1 |   1 | 0.0052356 |\n",
    "|   1 |   0 |   0 | 0         |\n",
    "|   1 |   0 |   1 | 1         |\n",
    "|   1 |   1 |   0 | 1         |\n",
    "|   1 |   1 |   1 | 0         |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional probabilities by naïve summation\n",
    "\n",
    "We are interested in calculating the conditional distributions.\n",
    "For the moment we will attempt to find the conditional distribution\n",
    "$p(L\\mid C=\\text{high})$.\n",
    "\n",
    "We will compute $p(L\\mid C=\\text{high})$ by naïve summation.\n",
    "\n",
    "To do this, we will need to reconstruct each of the joint probabilities from our graph.\n",
    "Remember that we know that we know a factorization for the joint probabilities,\n",
    "specifically,\n",
    "\n",
    "$$p(B,T,O,C,V,S,H,L,A)=p(B\\mid O,T)p(T\\mid A)p(O\\mid V,S)p(C\\mid V)p(V\\mid H,L)p(S\\mid H,L)p(H)p(L)p(A)$$\n",
    "\n",
    "To calculate this, we will need the factor multiplication operation we implemented in the previous tutorial (02). We called this operation a `factor join`. Below, we included our implementation of the function `join`. However, we recommend you use your code, so you can better test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(f1, f2, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f1`, first factor to be joined.\n",
    "    `f2`, second factor to be joined.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor with a join of f1 and f2\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, we need to determine the domain of the new factor. It will be union of the domain in f1 and f2\n",
    "    # But it is important to eliminate the repetitions\n",
    "    common_vars = list(f1['dom']) + list(set(f2['dom']) - set(f1['dom']))\n",
    "    \n",
    "    # We will build a table from scratch, starting with an empty list. Later on, we will transform the list into a odict\n",
    "    table = list()\n",
    "    \n",
    "    # Here is where the magic happens. The product iterator will generate all combinations of varible values \n",
    "    # as specified in outcomeSpace. Therefore, it will naturally respect observed values\n",
    "    for entries in product(*[outcomeSpace[node] for node in common_vars]):\n",
    "        \n",
    "        # We need to map the entries to the domain of the factors f1 and f2\n",
    "        entryDict = dict(zip(common_vars, entries))\n",
    "        f1_entry = (entryDict[var] for var in f1['dom'])\n",
    "        f2_entry = (entryDict[var] for var in f2['dom'])\n",
    "        \n",
    "        # Insert your code here\n",
    "        p1 = prob(f1, *f1_entry)           # Use the fuction prob to calculate the probability in factor f1 for entry f1_entry \n",
    "        p2 = prob(f2, *f2_entry)           # Use the fuction prob to calculate the probability in factor f2 for entry f2_entry \n",
    "        \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, p1 * p2))\n",
    "    return {'dom': tuple(common_vars), 'table': odict(table)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Now, implement a function that calculates the full joint probaility by multiplying all conditional distributions estimated from data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_joint(outcomeSpace, cond_tables=cond_tables_ml):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `outcomeSpace`, dictionary with domain of each variable\n",
    "    `cond_tables`, conditional probability distributions estimated from data\n",
    "    \n",
    "    Returns a new factor with full joint distribution\n",
    "    \"\"\"    \n",
    "    p = join(cond_tables['B'],  cond_tables['T'], outcomeSpace)\n",
    "    p = join(p, cond_tables['O'], outcomeSpace)\n",
    "    None                          # Complete the code for the remaining tables. 6 lines\n",
    "    return p\n",
    "\n",
    "#########################\n",
    "# Test code\n",
    "#########################\n",
    "p = p_joint(outcomeSpace)\n",
    "printFactor(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct implementation should provide the following output. Notice the size of this table as well as some very small probability values. We can realize how difficult it is to elicit such a probability table from a domain expert. It is much easier to work with smaller conditional tables.\n",
    "\n",
    "```\n",
    "|   O |   T |   B |   A |   V |   S |   C |   H |   L |          Pr |\n",
    "|-----+-----+-----+-----+-----+-----+-----+-----+-----+-------------|\n",
    "|   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 | 0.000363366 |\n",
    "|   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   1 | 0           |\n",
    "|   0 |   0 |   0 |   0 |   0 |   0 |   0 |   1 |   0 | 0.0249977   |\n",
    "|   0 |   0 |   0 |   0 |   0 |   0 |   0 |   1 |   1 | 0.00277599  |\n",
    "|   0 |   0 |   0 |   0 |   0 |   0 |   1 |   0 |   0 | 1.66682e-05 |\n",
    "|   0 |   0 |   0 |   0 |   0 |   0 |   1 |   0 |   1 | 0           |\n",
    "|   0 |   0 |   0 |   0 |   0 |   0 |   1 |   1 |   0 | 0.00114668  |\n",
    "|   0 |   0 |   0 |   0 |   0 |   0 |   1 |   1 |   1 | 0.000127339 |\n",
    "|   0 |   0 |   0 |   0 |   0 |   0 |   2 |   0 |   0 | 6.66726e-06 |\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answering Probabilistic Queries\n",
    "\n",
    "Given the joint distribution, we can answer any probabilistic queries we like. For instance, the query we posed before, $p(L\\mid C=\\text{high})$.\n",
    "\n",
    "We will need to eliminate variables through marginalization as well as observing evidence and renormalizing. We have implemented three functions to perform these tasks in the tutorial 02. We include our code belllow, but strongly recommend you to use your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evidence(var, e, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `var`, a valid variable identifier.\n",
    "    `e`, the observed value for var.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns dictionary with a copy of outcomeSpace with var = e\n",
    "    \"\"\"    \n",
    "    newOutcomeSpace = outcomeSpace.copy()      # Make a copy of outcomeSpace with a copy to method copy(). 1 line\n",
    "    newOutcomeSpace[var] = (e,)                # Replace the domain of variable var with a tuple with a single element e. 1 line\n",
    "    return newOutcomeSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginalize(f, var, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be marginalized.\n",
    "    `var`, variable to be summed out.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor f' with dom(f') = dom(f) - {var}\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Let's make a copy of f domain and convert it to a list. We need a list to be able to modify its elements\n",
    "    new_dom = list(f['dom'])\n",
    "    \n",
    "    new_dom.remove(var)            # Remove var from the list new_dom by calling the method remove(). 1 line\n",
    "    table = list()                 # Create an empty list for table. We will fill in table from scratch. 1 line\n",
    "    for entries in product(*[outcomeSpace[node] for node in new_dom]):\n",
    "        s = 0;                     # Initialize the summation variable s. 1 line\n",
    "\n",
    "        # We need to iterate over all possible outcomes of the variable var\n",
    "        for val in outcomeSpace[var]:\n",
    "            # To modify the tuple entries, we will need to convert it to a list\n",
    "            entriesList = list(entries)\n",
    "            # We need to insert the value of var in the right position in entriesList\n",
    "            entriesList.insert(f['dom'].index(var), val)\n",
    "                      \n",
    "            p = prob(f, *tuple(entriesList))     # Calculate the probability of factor f for entriesList. 1 line\n",
    "            s = s + p                            # Sum over all values of var by accumulating the sum in s. 1 line\n",
    "            \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, s))\n",
    "    return {'dom': tuple(new_dom), 'table': odict(table)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be normalized.\n",
    "    \n",
    "    Returns a new factor f' as a copy of f with entries that sum up to 1\n",
    "    \"\"\" \n",
    "    table = list()\n",
    "    sum = 0\n",
    "    for k, p in f['table'].items():\n",
    "        sum = sum + p\n",
    "    for k, p in f['table'].items():\n",
    "        table.append((k, p/sum))\n",
    "    return {'dom': f['dom'], 'table': odict(table)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Now it is your turn, implement a function `query` that receives as arguments a list of variables and a list of evidence and returns $P(variables|evidence)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(p, outcomeSpace, q_vars, **q_evi):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `p`, probability table to query.\n",
    "    `outcomeSpace`, dictionary will variable domains\n",
    "    `q_vars`, list of variables in query head\n",
    "    `q_evi`, dictionary of evidence in the form of variables names and values\n",
    "    \n",
    "    Returns a new factor NORMALIZED factor will all hidden variables eliminated as evidence set as in q_evi\n",
    "    \"\"\"     \n",
    "    \n",
    "    # Let's make a copy of these structures, since we will reuse the variable names\n",
    "    pm = p.copy()\n",
    "    outSpace = outcomeSpace.copy()\n",
    "    \n",
    "    # First, we set the evidence \n",
    "    None                                                       # Set the evidence var_evi = e. 2 lines\n",
    "        \n",
    "    # Second, we eliminate hidden variables NOT in the query\n",
    "    None                                                       # Marginalize to eliminate variable var. 3 lines\n",
    "            \n",
    "    # Third, return a normalized factor with the query answer\n",
    "    return None\n",
    "\n",
    "#########################\n",
    "# Test code\n",
    "#########################\n",
    "            \n",
    "printFactor(query(p, outcomeSpace, 'L', C=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct then you should see the following output:\n",
    "\n",
    "```\n",
    "|   L |        Pr |\n",
    "|-----+-----------|\n",
    "|   0 | 0.947912  |\n",
    "|   1 | 0.0520882 |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional independence\n",
    "\n",
    "In this part, we will numerically estimate conditional independences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Show or refute  the conditional independences in the theory tutorial numerically. i.e. \n",
    "determine whether\n",
    "\n",
    "1. $H \\indep L$\n",
    "2. $H \\indep A$\n",
    "3. $C \\indep L$\n",
    "\n",
    "We can do this by examining the conditional versus marginal probabilities, e.g. \n",
    "\n",
    "$$H \\indep L\\Rightarrow p(H,L)=p(H)p(L)$$\n",
    "\n",
    "Or,\n",
    "\n",
    "$$H \\indep L \\Rightarrow p(H|L)=p(H).$$\n",
    "\n",
    "It is your turn, we will leave three blank cells for you to develop your code. Use the functions we have implemented in the tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "198px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "783px",
    "left": "0px",
    "right": "1346.87px",
    "top": "108px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
