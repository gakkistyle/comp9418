{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Sample Exam\n",
    "\n",
    "**COMP9418 - Advanced Topics in Statistical Machine Learning**\n",
    "\n",
    "**University of New South Wales**\n",
    "\n",
    "**7th December, 2020**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing with reading this, please read and acknowledge the following (double-click on this cell and put an `X` between the brackets `[X]`:\n",
    "    \n",
    "- [ ] <span style=\"color:red\">I acknowledge that I will complete all of the work I submit for this exam without assistance from anyone else.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Instructions\n",
    "\n",
    "1. This exam will last for 24 hours, starting 7/12/2020 at 00:00:01 AEST and ending 7/12/2020 at 23:59:59 AEST.\n",
    "2. Questions will be answered from 9 am to 9 pm AEST. Questions should be posted in the  [WebCMS forum](https://webcms3.cse.unsw.edu.au/COMP9418/20T3/forums/) or sent by email to cs9418@cse.unsw.edu.au.\n",
    "3. All answers must be provided in this Jupyter notebook. \n",
    "4. You must use the cells provided to answer the questions. Use markdown cells for textual answers and code cells for programming answers.\n",
    "5. Submit this exam by give (command line or WebCMS) before the deadline. No late submissions will be accepted.\n",
    "6. The exam will have three parts: Multiple choice questions (20%). Questions that require a textual answer (50%). Programming questions in Python (30%).\n",
    "7. This exam is an open book exam. You are permitted to access papers and books as well as the course materials, including slides and solved tutorials.\n",
    "8. You are not permitted to communicate (email, phone, message, talk, etc.) with anyone during the exam, except COMP9418 staff via email or forum.\n",
    "9. Deliberate violation of exam conditions will be referred to Student Integrity as serious misconduct.\n",
    "10. This exam has eight questions. The total number of marks is 100.\n",
    "11. Type your student number and name on the next cell.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student identification\n",
    "\n",
    "**Name:** <span style=\"color:red\">Put your name here</span>\n",
    "\n",
    "**Student ID:** <span style=\"color:red\">Put your zID here</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 [20 marks]\n",
    "\n",
    "Part 1 is composed of four multiple-choice questions of five marks each. To answer each question, double-click the cell with the alternatives and write an `X` between the `[ ]` of the chosen option.\n",
    "\n",
    "This is an example before inserting `X`\n",
    "\n",
    "1. [ ] Alternative one\n",
    "2. [ ] Alternative two\n",
    "\n",
    "This is an example after inserting `X`\n",
    "\n",
    "1. [X] Alternative one\n",
    "2. [ ] Alternative two\n",
    "\n",
    "For all four questions, choose only one among the five alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 1 [5 marks]\n",
    "\n",
    "Suppose you have an extensive Bayesian network and you want to use it to do classification. In summary, you have a query node $Q$ representing a discrete variable with a domain size of $|Q|$. Your queries are MPE instantiation queries in the form:\n",
    "\n",
    "$$argmax_q P(Q=q|X_1=x_{i1}, X_2=x_{i2}, \\ldots, X_n=x_{in})$$\n",
    "\n",
    "where $X_1, \\ldots, X_n$ are the remaining variables in the network and $x_{i1}, \\ldots, x_{in}$ are the values corresponding to the test example $i$ for the variables $X_1, \\ldots, X_n$, respectively. Assume that your test set is complete, i.e., each test example has values for all network variables but the query $Q$.\n",
    "\n",
    "Due to the size of the network, you need to speed up this computation. Because of all variables but $Q$ are instantiated, you think you can reduce the query to:\n",
    "\n",
    "$$argmax_q P(Q=q|S(\\textbf{X})=\\textbf{x}_i^s))$$\n",
    "\n",
    "where $S(\\textbf{X})$ is a subset of variables of the network and $\\textbf{x}_i^s$ is a subset of values from example $i$ that matches the variables in $S(\\textbf{X})$.\n",
    "\n",
    "Choose the correct alternative:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [ ] $S(\\textbf{X})$ is the set of parent nodes of $Q$. When we set evidence for all parents of a node $Q$, the CPT of $Q$ reduces to $|Q|$ entries (for instance, 2 if $Q$ is a binary variable). The entry with the highest probability is the answer for the MPE query.\n",
    "2. [ ] $S(\\textbf{X})$ is the set of parent and child nodes of $Q$. When we set evidence for all parents and children of a node, we d-separate this node from the remaining of the network.\n",
    "3. [X] $S(\\textbf{X})$ is the set of parents, children and spouses of $Q$. Therefore $S(\\textbf{X})$ corresponds to the Markov blanket of $Q$.\n",
    "4. [ ] We cannot predefine $S(\\textbf{X})$ for given node $Q$ and a general Bayesian network. We need to run the d-separation algorithm and verify which nodes are independent of $Q$.\n",
    "5. [ ] We have to run an inference algorithm since independence is a dynamic concept. Independent variables can become dependent, given evidence and vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 2 [5 marks]\n",
    "\n",
    "Choose the **incorrect** alternative regarding the differences between Belief Propagation (BP), Iterative Belief Propagation (IBP - also known as Loopy Belief Propagation) and Generalized Belief Propagation (GBP - also known as Iterative Joingraph Propagation):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [ ] BP is restricted to polytrees while IBP and GBP can be applied to general networks.\n",
    "2. [ ] In BP, there is always a root or leaf node with a single neighbour that we can use to start to send messages. In IBP and GPB, such nodes may not exist. However, we initialize all messages with a value, so all nodes are allowed to send an initial message.\n",
    "3. [ ] BP provides exact results, that is, the computed marginals (beliefs) are correct. IBP and GBP do not have the same guarantees, and the beliefs are usually approximations of the true marginals.\n",
    "4. [ ] BP converges in a single iteration. IBP and GBP need a convergence criterium, so these methods iterate until such criterium is met.\n",
    "5. [X] When sending a message from a node *X* to a node *Y*, BP *X*'s message is the multiplication of incoming messages from all neighbours of *X* (including *Y*) by the factors associated with *X*. In the case of evidence, it also multiplies by the evidence indicator associated with *X*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 3 [5 marks]\n",
    "\n",
    "Suppose you use a jointree algorithm to make inference. However, the jointree $J$ with the lowest width does not have clusters that include all variables that will be present in the queries. For instance, you may want to compute $P(\\textbf{X})$ for a set of variables $\\textbf{X}$. However, there is no cluster $\\textbf{C}_i$ such that $\\textbf{X} \\subseteq \\textbf{C}_i$.\n",
    "\n",
    "![Jointree question 4](img/Question3.png)\n",
    "\n",
    "For the jointree above, you may be interested in the query $P(GC)$. Therefore $\\textbf{X} = GC$. \n",
    "\n",
    "Select the option with the **correct** alternative:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [ ] You can select a set of $k$ clusters, say, $\\textbf{C}_1, ..., \\textbf{C}_k$ such that $\\textbf{X} \\subseteq \\textbf{C}_1 \\cup, ..., \\cup \\textbf{C}_k$. To answer the queries, we join the marginals computed in $J$ for these clusters and eliminate the variables not present in $\\textbf{X}$. In the example above, you could join the marginals for $FDG$ and $ACE$ and remove variables $F, D, A$ and $E$.\n",
    "2. [ ] You can manipulate $J$ by adding to a chosen cluster $\\textbf{C}_i$ the variables in the set $\\textbf{X} \\cap \\textbf{C}_i$. No further modification of $J$ is needed. You compute the messages after manipulating $J$. In the example above, you could add the variable $C$ to the cluster $FDG$.\n",
    "3. [ ] You can manipulate $J$ by merging a cluster $\\textbf{C}_i$ with other clusters of $J$ such that the resulting cluster has all variables in $X$. No further modification of $J$ is needed. You compute the messages after manipulating $J$. In the example above, you could replace cluster $FDG$ with $FDG \\cup ACE$.\n",
    "4. [ ] You cannot use $J$ to answer these queries, you will need to find a different jointree.\n",
    "5. [X] None of the above alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 4 [5 marks]\n",
    "\n",
    "Which one of the following schemes converts a Bayesian network structure $G$ to a valid joingraph $U$? Choose the correct alternative. (Remember that $X$'s family is a set of nodes that includes $X$ and its parents if any)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [ ] For each node $X_i$ in $G$, define a cluster $\\textbf{C}_i$ over $X_i$’s family. Connect $\\textbf{C}_i$ and $\\textbf{C}_j$ if $X_j$ is a parent of $X_i$ in $G$, and define the separator to be the $\\{X_j\\}$.\n",
    "2. [ ] For each node $X_i$ in $G$, define a cluster $\\textbf{C}_i$ over $X_i$’s family. Connect $\\textbf{C}_i$ and $\\textbf{C}_j$ if $X_j$ is a parent of $X_i$ in $G$, and define the separator to be the intersection of the clusters.\n",
    "3. [ ] For each node $X_i$ in $G$, define a cluster $\\textbf{C}_i$ over $X_i$’s family. Connect $\\textbf{C}_i$ and $\\textbf{C}_j$ if $X_j$ is a parent of $X_i$ in $G$, and define the separator to be the $\\{X_i\\}$.\n",
    "4. [ ] For each node $X_i$ in $G$, define a cluster $\\textbf{C}_i$ over $X_i$’s family. Connect $\\textbf{C}_i$ and $\\textbf{C}_j$ if $X_j$ is a parent of $X_i$ in $G$, and define the separator to be the $\\{X_i,X_j\\}$.\n",
    "5. [ ] None of the above alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Part 2 [50 marks]\n",
    "\n",
    "Part 2 is composed of two open questions of 25 marks each. To answer each question, edit the markdown cell after the question statement and insert your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 5 [25 marks]\n",
    "\n",
    "Jack has three coins $C_1$, $C_2$ and $C_3$ with $p_1$, $p_2$ and $p_3$ as their corresponding probabilities of landing heads. Jack flips coin $C_1$ twice and then decides, based on the outcome, whether to flip coin $C_2$ or $C_3$ next. In particular, if the two $C_1$ flips come out the same, Jack flips coin $C_2$ three times next. However, if the $C_1$ flips come out different, he flips coin $C_3$ three times next. Given the outcome of Jack's last three flips, we want to know whether his first two flips came out the same. \n",
    "\n",
    "1. [**5 Marks**] Show a Bayesian network structure (graph) for this problem. **Briefly** explain your network.\n",
    "2. [**5 Marks**] Show the network conditional probability tables (CPTs) for all variables. If you have parameters that are shared among variables, define the CPT once and indicate which variables use that CPT.\n",
    "3. [**5 Marks**] Provide a query that solves this problem.\n",
    "4. [**10 Marks**] What is the solution to this problem assuming that $p_1 = 0.4, p_2 = 0.6$ and $p_3 = 0.1$, and the last three flips came out as follows (show your work. This item can be solved as a simulation exercise -- you provide a step-by-step solution -- or a programming exercise -- you provide a program that computes a step-by-step solution)\n",
    "    1. tails, heads, tails\n",
    "    2. tails, tails, tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"187pt\" height=\"163pt\"\n",
       " viewBox=\"0.00 0.00 186.82 163.47\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 159.47)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-159.47 182.82,-159.47 182.82,4 -4,4\"/>\n",
       "<!-- F1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>F1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"51.76\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"51.76\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">F1</text>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"89.81\" cy=\"-71.63\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"89.81\" y=\"-67.93\" font-family=\"Times,serif\" font-size=\"14.00\">C</text>\n",
       "</g>\n",
       "<!-- F1&#45;&gt;C -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>F1&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63.39,-34.38C66.19,-38.33 69.25,-42.64 72.25,-46.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"69.62,-49.22 78.26,-55.35 75.33,-45.17 69.62,-49.22\"/>\n",
       "</g>\n",
       "<!-- F2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>F2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"129.62\" cy=\"-19.31\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"129.62\" y=\"-15.61\" font-family=\"Times,serif\" font-size=\"14.00\">F2</text>\n",
       "</g>\n",
       "<!-- F2&#45;&gt;C -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>F2&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M117.24,-35.58C114.37,-39.35 111.25,-43.45 108.18,-47.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"105.31,-45.47 102.04,-55.55 110.88,-49.71 105.31,-45.47\"/>\n",
       "</g>\n",
       "<!-- F3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>F3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"88.49\" cy=\"-137.47\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"88.49\" y=\"-133.77\" font-family=\"Times,serif\" font-size=\"14.00\">F3</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;F3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>C&#45;&gt;F3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M89.44,-89.97C89.32,-95.82 89.19,-102.44 89.06,-108.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"85.56,-109.16 88.85,-119.23 92.55,-109.3 85.56,-109.16\"/>\n",
       "</g>\n",
       "<!-- F4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>F4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"151.82\" cy=\"-93.64\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"151.82\" y=\"-89.94\" font-family=\"Times,serif\" font-size=\"14.00\">F4</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;F4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>C&#45;&gt;F4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M113.96,-80.2C115.23,-80.65 116.5,-81.11 117.79,-81.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.04,-85.01 127.63,-85.06 119.38,-78.41 117.04,-85.01\"/>\n",
       "</g>\n",
       "<!-- F5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>F5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-91.3\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-87.6\" font-family=\"Times,serif\" font-size=\"14.00\">F5</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;F5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>C&#45;&gt;F5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M65.35,-79.29C64.07,-79.69 62.77,-80.1 61.47,-80.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"60,-77.3 51.5,-83.63 62.09,-83.98 60,-77.3\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fca1528e940>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer for item 1 - graph\n",
    "\n",
    "# Define your graph here\n",
    "graph = {\n",
    "    'F1': ['C'],\n",
    "    'F2': ['C'],\n",
    "    'C':['F3','F4','F5'],\n",
    "    'F3':[],\n",
    "    'F4':[],\n",
    "    'F5':[]\n",
    "}\n",
    "\n",
    "# Do not modify this code, it simply plots the graph above\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph(engine=\"neato\", comment='Direct graph example')\n",
    "dot.attr(overlap=\"false\", splines=\"true\")\n",
    "\n",
    "for v in graph.keys():\n",
    "    dot.node(v)\n",
    "    # dot.node(str(v))              # position the nodes in random order\n",
    "\n",
    "for v in graph.keys():\n",
    "    for w in graph[v]:\n",
    "        dot.edge(v, w)\n",
    "\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer for item 1 - Brief explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer for item 2\n",
    "\n",
    "This is a sample table\n",
    "\n",
    "|  $F1$  | $P(F1)$ |\n",
    "|  :-:  |  :-:   |\n",
    "| heads |  $p1$   |\n",
    "| tails |  $1-p1$   |\n",
    "\n",
    "|  $F2$  | $P(F2)$ |\n",
    "|  :-:  |  :-:   |\n",
    "| heads |  $p1$   |\n",
    "| tails |  $1-p1$   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer for item 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer for item 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 6 [25 marks]\n",
    "\n",
    "Markov chains were subject of two lectures: 8 and 14. Lecture 8 defined the chain and their properties such as regularity and peridiocidity as well as the concept of stationary distribution. Lecture 14 covered Markov Chain Monte Carlo methods such as Gibbs sampling. However, these techniques seem disconnected since Gibbs sampling is an approximate inference algorithm, while Markov chains are stochastic models. In this question, we ask you to elucidate the connections between these two methods.\n",
    "\n",
    "Remember that Markov chains are characterized by the transition probabilities between states, frequently organized in the form of a transition matrix. Answer **briefly**\n",
    "\n",
    "1. [**5 marks**] What is a state for the Gibbs chain? \n",
    "2. [**5 marks**] What is the transition matrix for the Gibbs chain? How big is this matrix? What are the transition probabilities?\n",
    "3. [**5 marks**] What is the stationary distribution for the Gibbs chain? What is its importance for sampling and its connection to mixing?\n",
    "4. [**10 marks**] What makes Gibbs sampling suitable for making inference on Markov networks compared to forward and rejection sampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer for item 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer for item 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer for item 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer for item 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Part 3 [30 marks]\n",
    "\n",
    "Part 3 is composed of two programming questions of 15 marks each. Use the code cell after each question statement to enter your answer. You can use the code of the tutorials in your answers. You may import any libraries that were used in the tutorials, but no others.\n",
    "\n",
    "Load the next cell. The Bayesian network example will be used in both exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict as odict\n",
    "from math import log\n",
    "# x = log(y, 2) to compute log y in base 2\n",
    "\n",
    "graph = {\n",
    "    'A': ['B'],\n",
    "    'B': ['E'],\n",
    "    'C': ['E', 'F'],\n",
    "    'D': ['G'],\n",
    "    'E': ['G', 'H'],\n",
    "    'F': [],\n",
    "    'G': ['I'],\n",
    "    'H': [],\n",
    "    'I': [],    \n",
    "}\n",
    "\n",
    "outcomeSpace = dict(\n",
    "    A=(0,1),\n",
    "    B=(0,1),\n",
    "    C=(0,1),\n",
    "    D=(0,1),\n",
    "    E=(0,1),\n",
    "    F=(0,1),\n",
    "    G=(0,1),\n",
    "    H=(0,1),\n",
    "    I=(0,1),\n",
    ")\n",
    "\n",
    "factors = {\n",
    "    'A': {\n",
    "        'dom': ('A',), \n",
    "        'table': odict([\n",
    "            ((0,), 0.80),\n",
    "            ((1,), 0.20),\n",
    "        ])\n",
    "    },\n",
    "    \n",
    "    'B' : {\n",
    "        'dom': ('A', 'B'),\n",
    "        'table': odict([\n",
    "            ((0, 0), 0.95),\n",
    "            ((0, 1), 0.05),\n",
    "            ((1, 0), 0.80),\n",
    "            ((1, 1), 0.20),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'C': {\n",
    "        'dom': ('C',), \n",
    "        'table': odict([\n",
    "            ((0,), 0.50),\n",
    "            ((1,), 0.50),\n",
    "        ])\n",
    "    },\n",
    "    \n",
    "    'D': {\n",
    "        'dom': ('D',), \n",
    "        'table': odict([\n",
    "            ((0,), 0.40),\n",
    "            ((1,), 0.60),\n",
    "        ])\n",
    "    },\n",
    "    \n",
    "    'E': {\n",
    "        'dom': ('B', 'C', 'E'), \n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 0.05),\n",
    "            ((0, 0, 1), 0.95),\n",
    "            ((0, 1, 0), 0.99),\n",
    "            ((0, 1, 1), 0.01),\n",
    "            ((1, 0, 0), 0.80),\n",
    "            ((1, 0, 1), 0.20),\n",
    "            ((1, 1, 0), 0.50),\n",
    "            ((1, 1, 1), 0.50),\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    'F' : {\n",
    "        'dom': ('C', 'F'),\n",
    "        'table': odict([\n",
    "            ((0, 0), 0.10),\n",
    "            ((0, 1), 0.90),\n",
    "            ((1, 0), 0.40),\n",
    "            ((1, 1), 0.60),\n",
    "        ])\n",
    "    },    \n",
    "\n",
    "    'G': {\n",
    "        'dom': ('D', 'E', 'G'), \n",
    "        'table': odict([\n",
    "            ((0, 0, 0), 0.15),\n",
    "            ((0, 0, 1), 0.85),\n",
    "            ((0, 1, 0), 0.70),\n",
    "            ((0, 1, 1), 0.30),\n",
    "            ((1, 0, 0), 0.80),\n",
    "            ((1, 0, 1), 0.20),\n",
    "            ((1, 1, 0), 0.25),\n",
    "            ((1, 1, 1), 0.75),\n",
    "        ])\n",
    "    },\n",
    "    \n",
    "    'H' : {\n",
    "        'dom': ('E', 'H'),\n",
    "        'table': odict([\n",
    "            ((0, 0), 0.50),\n",
    "            ((0, 1), 0.50),\n",
    "            ((1, 0), 0.45),\n",
    "            ((1, 1), 0.55),\n",
    "        ])\n",
    "    }, \n",
    "    \n",
    "    'I' : {\n",
    "        'dom': ('G', 'I'),\n",
    "        'table': odict([\n",
    "            ((0, 0), 0.60),\n",
    "            ((0, 1), 0.40),\n",
    "            ((1, 0), 0.55),\n",
    "            ((1, 1), 0.45),\n",
    "        ])\n",
    "    }\n",
    "}\n",
    "\n",
    "dataset = [\n",
    "    dict(A=1,B=1,C=0,D=1,E=0,F=1,G=1,H=1,I=1),\n",
    "    dict(A=0,B=1,C=1,D=1,E=1,F=1,G=1,H=0,I=0),\n",
    "    dict(A=1,B=0,C=1,D=0,E=0,F=0,G=0,H=1,I=0),\n",
    "    dict(A=1,B=0,C=0,D=1,E=0,F=0,G=0,H=0,I=1),\n",
    "    dict(A=0,B=1,C=0,D=1,E=0,F=1,G=1,H=1,I=1),\n",
    "    dict(A=0,B=0,C=1,D=1,E=1,F=1,G=0,H=0,I=1),\n",
    "    dict(A=1,B=1,C=1,D=0,E=1,F=0,G=1,H=1,I=0),\n",
    "    dict(A=0,B=1,C=0,D=1,E=1,F=1,G=0,H=0,I=1),\n",
    "    dict(A=0,B=0,C=0,D=0,E=1,F=0,G=1,H=1,I=0),\n",
    "    dict(A=0,B=0,C=0,D=1,E=1,F=0,G=0,H=0,I=0),  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 7 [15 marks]\n",
    "\n",
    "In Question 1 of this exam, we asked you how we can speed up MPE queries in the case we have observed all variables but the query variable. In this question, you have to provide a Python function that implements such an efficient inference algorithm.\n",
    "\n",
    "Implement a function `MPE_classify(G, factors, outcomeSpace, q_var, q_evi)` that returns the most likely instantiation of the variable `q_var` given the evidence list `q_evi` for a graph `G` with a factor dictionary `factors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'examples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6493d27ac5a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMPE_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcomeSpace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'E'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'examples' is not defined"
     ]
    }
   ],
   "source": [
    "# Write our answer here\n",
    "\n",
    "def MPE_classify(G, factors, outcomeSpace, q_var, q_evi):\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############\n",
    "# Test code\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    print(MPE_classify(graph, factors, outcomeSpace, 'E', examples[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 8 [15 marks]\n",
    "\n",
    "A central component of learning structures from data is the computation of the log-likelihood functions for a Bayesian network $G$ and a dataset $D$. An important result is that such log-likelihood corresponds to a sum of terms, one for each family in the network:\n",
    "\n",
    "$$LL(G;D)=-N \\sum_{X\\textbf{U}} H_D(X|\\textbf{U})$$\n",
    "\n",
    "where $H_D(X|\\textbf{U})$ is the conditional entropy for the family $X\\textbf{U}$.\n",
    "\n",
    "Implement a Python function `LL(factors, outcomeSpace, dataset)` that computes the log-likelihood of a graph $G$ defined over a dictionary of factors `factors` using the dataset `dataset`. Define an intermediate function `entropy(factors, X, outcomeSpace, dataset)` that computes the conditional entropy for the family of variable `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-80.20608933243739\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "def transposeGraph(G):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `G`, an adjacency list representation of a graph\n",
    "    \"\"\"      \n",
    "    GT = dict((v, []) for v in G)\n",
    "    for v in GT.keys():   # Implement your code to transpose G and store the response in GT\n",
    "        for w in G.keys():\n",
    "            if v in G[w]:\n",
    "                GT[v].append(w)\n",
    "    return GT\n",
    "\n",
    "def entropy(Gt, X, outcomeSpace, dataset):\n",
    "    e = 0\n",
    "    for entries in product(*[outcomeSpace[node] for node in Gt[X]]):\n",
    "        for x in outcomeSpace[X]:\n",
    "            c_u = 0\n",
    "            c_x_u = 0\n",
    "            for i in range(len(dataset)):\n",
    "                if all(dataset[i][Gt[X][j]] == entries[j] for j in range(len(Gt[X]))):\n",
    "                    c_u += 1\n",
    "                    if dataset[i][X] == x:\n",
    "                        \n",
    "                        c_x_u += 1\n",
    "            if c_x_u > 0:\n",
    "                p_x__u = c_x_u / c_u\n",
    "                p_x_u = c_x_u / len(dataset)\n",
    "                e += p_x_u * log(p_x__u, 2)\n",
    "    return -e\n",
    "\n",
    "def LL(G, outcomeSpace, dataset):\n",
    "    ll = 0\n",
    "    Gt = transposeGraph(G)\n",
    "    for var in Gt.keys():\n",
    "        ll += entropy(Gt, var, outcomeSpace, dataset)\n",
    "    return -ll * len(dataset)\n",
    "\n",
    "\n",
    "\n",
    "############\n",
    "# Test code\n",
    "\n",
    "print(LL(graph, outcomeSpace, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "198px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "783px",
    "left": "0px",
    "right": "1346.87px",
    "top": "108px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
